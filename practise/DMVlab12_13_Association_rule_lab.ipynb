{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be51cce-23a3-469f-a7bf-a0a12d511f16",
   "metadata": {},
   "source": [
    "### This assignment will be divided into two parts: apriori algorithm and FPGrowth algorithm. In this assignment, we will use the movielens 100k dataset (100k, not other versions!) First, we will provide some preprocessing codes, then you are expected to answer the subsequent questions. The dataset can be downloaded from this [LINK](https://grouplens.org/datasets/movielens/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6971e4-a0cf-461a-9935-c4e6aa36fa14",
   "metadata": {},
   "source": [
    "# Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin by installing the mlxtend library, which contains useful subroutines for our tasks\n",
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d63f2-d51c-4c13-a22a-6effdb397a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, make the necessary imports\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cacae",
   "metadata": {},
   "source": [
    "At this point, ensure you've downloaded the dataset into the same folder as this notebook. As a result, you should have a folder called `ml-100k` in this directory. You can then proceed with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65f6db-a78a-4c26-94fd-f0444b15e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and read the dataset\n",
    "data_file = 'ml-100k/u.data'\n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(data_file, sep='\\t', names=columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd125f-447d-4fc7-a290-7267d0e54ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep those interactions with rating larger than 3 to avoid complex computation\n",
    "filter_data = data[data['rating'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef2d9f-d34d-42a2-9d35-9ad6eaf3d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In association rules mining, usually, we don't care about personalisation. We can simply transfrom the dataset into the following format. \n",
    "# To match the lecture notes, we also call them transaction. Each element of a transaction list, represent the movies\n",
    "# watched by a unique user. \n",
    "unique_user = list(set(filter_data['user_id']))\n",
    "transaction_list = []\n",
    "for u in unique_user:\n",
    "    temp_trans = list(filter_data[filter_data['user_id']==u]['item_id'])\n",
    "    transaction_list.append(temp_trans)\n",
    "\n",
    "# We use the following transform function to process the transaction list.\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transaction_list).transform(transaction_list)\n",
    "print(te_ary.astype(\"int\"))\n",
    "# Each row represent one movie\n",
    "# print(te.columns_)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d75e8-bf50-4aa2-a182-097d74bf7781",
   "metadata": {},
   "source": [
    "# Part 1: apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb24b21-0a1e-451d-9f4c-a2d399fef9a1",
   "metadata": {},
   "source": [
    "## Use the apriori function from mlxtend.frequent_patterns. Find the frequent itemsets with support value larger than 0.1. How many are they? (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1591fa-c012-4cc2-b6de-e048f8fb69b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04be7041-7a40-452d-9240-40b94c056135",
   "metadata": {},
   "source": [
    "### Which item/itemsets has the largest support value? (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c183de2-94ed-4ffd-90a9-c9e8cc0f95d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b650233-159a-4d45-947e-db122b637eb8",
   "metadata": {},
   "source": [
    "### According to your surname, find your corresponding frequent item/itemset. (3 credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ad1c4-dee1-4617-b25e-cad67f724007",
   "metadata": {},
   "source": [
    "### Sort the frequent item returned from apriori from high to low, high at the top, low at the bottom. If the last letter of your surname is one of the following, find the corresponding item/itemsets with the given index:\n",
    "1. surname letter: n----> index 100\n",
    "2. surname letter: i----> index 200\n",
    "3. surname letter: o----> index 300\n",
    "4. surname letter: u----> index 400\n",
    "5. surname letter: g----> index 500\n",
    "\n",
    "You should use .iloc[100] or .iloc[200] etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc842c64-ace3-45cf-af2f-e9f689907f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a33fa81-6ea5-4c10-a6db-aaf714f94c5c",
   "metadata": {},
   "source": [
    "### Calculate the average rating (keep 3 decimals) of your corresponding items. (Use the original dataframe to calculate the average rating instead of the filtered one.) If your corresponding index contains more than 1 item, you need to report each average rating. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993dff4-0325-41b7-b45f-4167ae235646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd1c8607-5b83-4932-8961-4b40f5949930",
   "metadata": {},
   "source": [
    "## Use the association_rules from mlxtend.frequent_patterns to compute frequent_itemsets using the metric 'confidence' and set the min_threshold=0.4. (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be8a95-32b7-419d-b268-cbd8a85e3280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e457eaee-7c32-4bc0-b75d-5baa3ee5ff86",
   "metadata": {},
   "source": [
    "## From the association_rules, which two movies are frequently co-watched? (3 credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e4fb1-40a5-40f5-8128-7f7f17ab45d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9342f160-28e5-4b72-b8c3-ba603ed8f597",
   "metadata": {},
   "source": [
    "# Part 2: FPGrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39808315-cd0c-41fb-91c1-a49f44cf078c",
   "metadata": {},
   "source": [
    "## Similar to how you use the apriori algorithm in the first part, use the FPGrowth to process the filtered dataframe by setting the min_support to 0.1. (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7202e9-78af-4bae-98b6-65acd9a57832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3033a56f-9790-4fe6-a4a2-6604b1e87b73",
   "metadata": {},
   "source": [
    "## Which item/itemset has the largest support value? (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10708c9e-d5d5-4a57-b95a-1e033e5eddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bba1eca9-2113-469c-8fc1-1f093436e324",
   "metadata": {},
   "source": [
    "## Use the assocation fules from mlxtend.frequent_patterns to process the data filtered by FPGrowth using the metric of confidence and min_threshold of 0.5. What is the shape of the dataframe? (1 credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bd199-7c34-4493-839c-5880be15ea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ef8ed8-3631-4809-9d7d-d908e8a94d08",
   "metadata": {},
   "source": [
    "## For the rules, if we want to keep those with support value larger than 0.15 and confidence large than 0.4. How many rows left? (2 credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdf6d6-05aa-4acd-acb6-f46f6cdfa0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e6aab8-15a7-4fd1-86d3-534825a3a125",
   "metadata": {},
   "source": [
    "## If a user has watched two movies whose ids are 96 and 50, and you want to recommend one more movie to them. Based on the rules, which one you will recommend? (You may answer this question from different perspectives.) (5 credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb29c8-9e69-4ba6-9345-e3bc8819fba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
